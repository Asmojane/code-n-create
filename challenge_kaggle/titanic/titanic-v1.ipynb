{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"dockerImageVersionId":30761,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-11T13:04:05.884674Z","iopub.execute_input":"2024-09-11T13:04:05.885110Z","iopub.status.idle":"2024-09-11T13:04:06.342801Z","shell.execute_reply.started":"2024-09-11T13:04:05.885067Z","shell.execute_reply":"2024-09-11T13:04:06.340948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n# Load the training and test datasets\ntrain_df = pd.read_csv('/kaggle/input/titanic/train.csv')\ntest_df = pd.read_csv('/kaggle/input/titanic/test.csv')\n\n# Display the first few rows of the training data\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-09-11T13:08:21.371043Z","iopub.execute_input":"2024-09-11T13:08:21.371766Z","iopub.status.idle":"2024-09-11T13:08:21.436914Z","shell.execute_reply.started":"2024-09-11T13:08:21.371715Z","shell.execute_reply":"2024-09-11T13:08:21.435596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fill missing values in 'Age' with the median\ntrain_df['Age'].fillna(train_df['Age'].median(), inplace=True)\ntest_df['Age'].fillna(test_df['Age'].median(), inplace=True)\n\n# Fill missing values in 'Fare' with the median\ntest_df['Fare'].fillna(test_df['Fare'].median(), inplace=True)\n\n# Fill missing values in 'Embarked' with the mode (most frequent value)\ntrain_df['Embarked'].fillna(train_df['Embarked'].mode()[0], inplace=True)\n\n# Drop the 'Cabin' column because it has too many missing values\ntrain_df.drop(columns=['Cabin'], inplace=True)\ntest_df.drop(columns=['Cabin'], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-09-11T13:08:53.987061Z","iopub.execute_input":"2024-09-11T13:08:53.987465Z","iopub.status.idle":"2024-09-11T13:08:54.012990Z","shell.execute_reply.started":"2024-09-11T13:08:53.987419Z","shell.execute_reply":"2024-09-11T13:08:54.011563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Encode 'Sex' (0 for male, 1 for female)\ntrain_df['Sex'] = train_df['Sex'].map({'male': 0, 'female': 1})\ntest_df['Sex'] = test_df['Sex'].map({'male': 0, 'female': 1})\n\n# Encode 'Embarked' (0 for S, 1 for C, 2 for Q)\ntrain_df['Embarked'] = train_df['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})\ntest_df['Embarked'] = test_df['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})","metadata":{"execution":{"iopub.status.busy":"2024-09-11T13:09:14.148059Z","iopub.execute_input":"2024-09-11T13:09:14.149329Z","iopub.status.idle":"2024-09-11T13:09:14.166451Z","shell.execute_reply.started":"2024-09-11T13:09:14.149264Z","shell.execute_reply":"2024-09-11T13:09:14.163983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create 'FamilySize' feature\ntrain_df['FamilySize'] = train_df['SibSp'] + train_df['Parch'] + 1\ntest_df['FamilySize'] = test_df['SibSp'] + test_df['Parch'] + 1\n\n# Extract 'Title' from names\ntrain_df['Title'] = train_df['Name'].apply(lambda x: x.split(',')[1].split('.')[0].strip())\ntest_df['Title'] = test_df['Name'].apply(lambda x: x.split(',')[1].split('.')[0].strip())\n\n# Replace rare titles with 'Other'\nrare_titles = ['Lady', 'Countess', 'Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona']\ntrain_df['Title'] = train_df['Title'].replace(rare_titles, 'Other')\ntest_df['Title'] = test_df['Title'].replace(rare_titles, 'Other')\n\n# Map titles to numerical values\ntitle_mapping = {'Mr': 0, 'Miss': 1, 'Mrs': 2, 'Master': 3, 'Other': 4}\ntrain_df['Title'] = train_df['Title'].map(title_mapping)\ntest_df['Title'] = test_df['Title'].map(title_mapping)","metadata":{"execution":{"iopub.status.busy":"2024-09-11T13:09:35.871119Z","iopub.execute_input":"2024-09-11T13:09:35.871660Z","iopub.status.idle":"2024-09-11T13:09:35.890819Z","shell.execute_reply.started":"2024-09-11T13:09:35.871613Z","shell.execute_reply":"2024-09-11T13:09:35.889693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Select features for clustering\nfeatures_for_clustering = train_df[['Pclass', 'Age', 'Fare', 'FamilySize']]\n\n# Now check for missing values\nprint(features_for_clustering.isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2024-09-11T13:09:49.501013Z","iopub.execute_input":"2024-09-11T13:09:49.501553Z","iopub.status.idle":"2024-09-11T13:09:49.512061Z","shell.execute_reply.started":"2024-09-11T13:09:49.501512Z","shell.execute_reply":"2024-09-11T13:09:49.510652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\n\n# Standardize the features for clustering\nscaler = StandardScaler()\nfeatures_for_clustering_scaled = scaler.fit_transform(train_df[['Pclass', 'Age', 'Fare', 'FamilySize']])\n\n# Apply KMeans clustering\nkmeans = KMeans(n_clusters=5, random_state=42)\ntrain_df['Cluster'] = kmeans.fit_predict(features_for_clustering_scaled)\n\n# Apply the same scaling and clustering to the test set\ntest_features_scaled = scaler.transform(test_df[['Pclass', 'Age', 'Fare', 'FamilySize']])\ntest_df['Cluster'] = kmeans.predict(test_features_scaled)\n\n# Visualize the clusters (optional, for understanding the distribution)\nplt.scatter(train_df['Fare'], train_df['Age'], c=train_df['Cluster'], cmap='viridis')\nplt.xlabel('Fare')\nplt.ylabel('Age')\nplt.title('Passenger Clusters based on Fare and Age')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-09-11T13:10:28.431774Z","iopub.execute_input":"2024-09-11T13:10:28.432223Z","iopub.status.idle":"2024-09-11T13:10:30.117164Z","shell.execute_reply.started":"2024-09-11T13:10:28.432170Z","shell.execute_reply":"2024-09-11T13:10:30.115942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fill missing values in 'Title' with the most common value in both train and test sets\nX_train['Title'] = X_train['Title'].fillna(X_train['Title'].mode()[0])\nX_test['Title'] = X_test['Title'].fillna(X_test['Title'].mode()[0])\n\n# Check again for missing values (should be 0 now)\nprint(X_train.isnull().sum())\nprint(X_test.isnull().sum())\n\n# Now proceed with training the model\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\n\n# Initialize the Random Forest model\nrf_model = RandomForestClassifier(n_estimators=300, max_depth=10, min_samples_split=5, random_state=42)\n\n# Evaluate the model using cross-validation\nscores = cross_val_score(rf_model, X_train, y_train, cv=5)\n\n# Print cross-validation scores and the mean accuracy\nprint(f'Cross-validation scores: {scores}')\nprint(f'Mean accuracy: {scores.mean() * 100:.2f}%')\n","metadata":{"execution":{"iopub.status.busy":"2024-09-11T13:16:20.402863Z","iopub.execute_input":"2024-09-11T13:16:20.403317Z","iopub.status.idle":"2024-09-11T13:16:23.825515Z","shell.execute_reply.started":"2024-09-11T13:16:20.403274Z","shell.execute_reply":"2024-09-11T13:16:23.823335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check for missing values in X_train\nprint(X_train.isnull().sum())\n","metadata":{"execution":{"iopub.status.busy":"2024-09-11T13:12:59.572763Z","iopub.execute_input":"2024-09-11T13:12:59.573185Z","iopub.status.idle":"2024-09-11T13:12:59.581276Z","shell.execute_reply.started":"2024-09-11T13:12:59.573145Z","shell.execute_reply":"2024-09-11T13:12:59.579907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fill missing values in 'Title' with the most common value (or with 'Other')\nX_train['Title'].fillna(X_train['Title'].mode()[0], inplace=True)\nX_test['Title'].fillna(X_test['Title'].mode()[0], inplace=True)\n\n# Check again for missing values\nprint(X_train.isnull().sum())\n","metadata":{"execution":{"iopub.status.busy":"2024-09-11T13:14:14.433292Z","iopub.execute_input":"2024-09-11T13:14:14.434330Z","iopub.status.idle":"2024-09-11T13:14:14.474792Z","shell.execute_reply.started":"2024-09-11T13:14:14.434275Z","shell.execute_reply":"2024-09-11T13:14:14.473145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create X_test by selecting relevant features\nX_test = test_df[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'FamilySize', 'Title', 'Cluster']]\n\n# Fill missing values in 'Title' with the most common value (or 'Other')\nX_test['Title'] = X_test['Title'].fillna(X_test['Title'].mode()[0])","metadata":{"execution":{"iopub.status.busy":"2024-09-11T13:15:49.398225Z","iopub.execute_input":"2024-09-11T13:15:49.398672Z","iopub.status.idle":"2024-09-11T13:15:49.407772Z","shell.execute_reply.started":"2024-09-11T13:15:49.398630Z","shell.execute_reply":"2024-09-11T13:15:49.406426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Define the hyperparameters grid to search\nparam_grid = {\n    'n_estimators': [100, 200, 300, 500],\n    'max_depth': [5, 10, 15, 20],\n    'min_samples_split': [2, 5, 10],\n    'min_samples_leaf': [1, 2, 4]\n}\n\n# Initialize the RandomForestClassifier\nrf_model = RandomForestClassifier(random_state=42)\n\n# Perform grid search with cross-validation\ngrid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\ngrid_search.fit(X_train, y_train)\n\n# Print the best hyperparameters and the best score\nprint(f\"Best hyperparameters: {grid_search.best_params_}\")\nprint(f\"Best cross-validation accuracy: {grid_search.best_score_ * 100:.2f}%\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-11T13:48:13.158269Z","iopub.execute_input":"2024-09-11T13:48:13.160520Z","iopub.status.idle":"2024-09-11T13:51:14.105546Z","shell.execute_reply.started":"2024-09-11T13:48:13.160406Z","shell.execute_reply":"2024-09-11T13:51:14.103700Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import xgboost as xgb\nfrom sklearn.model_selection import cross_val_score\n\n# Initialize XGBoost model\nxgb_model = xgb.XGBClassifier(n_estimators=300, max_depth=10, learning_rate=0.05, random_state=42)\n\n# Cross-validation for XGBoost\nscores = cross_val_score(xgb_model, X_train, y_train, cv=5)\n\n# Print cross-validation results\nprint(f'XGBoost cross-validation scores: {scores}')\nprint(f'Mean accuracy: {scores.mean() * 100:.2f}%')\n","metadata":{"execution":{"iopub.status.busy":"2024-09-11T13:57:56.397769Z","iopub.execute_input":"2024-09-11T13:57:56.398441Z","iopub.status.idle":"2024-09-11T13:57:58.025915Z","shell.execute_reply.started":"2024-09-11T13:57:56.398394Z","shell.execute_reply":"2024-09-11T13:57:58.023784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import VotingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nimport xgboost as xgb\n\n# Initialize models\nlogreg = LogisticRegression()\nrf = RandomForestClassifier(n_estimators=300, max_depth=10, random_state=42)\nxgb_model = xgb.XGBClassifier(n_estimators=300, max_depth=10, learning_rate=0.05, random_state=42)\n\n# Combine them using VotingClassifier\nensemble_model = VotingClassifier(estimators=[\n    ('lr', logreg),\n    ('rf', rf),\n    ('xgb', xgb_model)\n], voting='soft')\n\n# Cross-validation for the ensemble model\nscores = cross_val_score(ensemble_model, X_train, y_train, cv=5)\n\nprint(f'Ensemble model cross-validation scores: {scores}')\nprint(f'Mean accuracy: {scores.mean() * 100:.2f}%')\n ","metadata":{"execution":{"iopub.status.busy":"2024-09-11T13:58:27.563644Z","iopub.execute_input":"2024-09-11T13:58:27.564696Z","iopub.status.idle":"2024-09-11T13:58:34.557345Z","shell.execute_reply.started":"2024-09-11T13:58:27.564632Z","shell.execute_reply":"2024-09-11T13:58:34.556238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create age bins\ntrain_df['AgeBin'] = pd.cut(train_df['Age'], bins=[0, 12, 20, 40, 60, 80], labels=[0, 1, 2, 3, 4])\ntest_df['AgeBin'] = pd.cut(test_df['Age'], bins=[0, 12, 20, 40, 60, 80], labels=[0, 1, 2, 3, 4])\n","metadata":{"execution":{"iopub.status.busy":"2024-09-11T13:59:02.998449Z","iopub.execute_input":"2024-09-11T13:59:02.998913Z","iopub.status.idle":"2024-09-11T13:59:03.010603Z","shell.execute_reply.started":"2024-09-11T13:59:02.998873Z","shell.execute_reply":"2024-09-11T13:59:03.009037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import StackingClassifier\nfrom sklearn.linear_model import LogisticRegression\n\n# Define base models\nestimators = [\n    ('rf', RandomForestClassifier(n_estimators=300, max_depth=10, random_state=42)),\n    ('xgb', xgb.XGBClassifier(n_estimators=300, max_depth=10, learning_rate=0.05, random_state=42))\n]\n\n# Define Stacking model with Logistic Regression as meta-model\nstacking_model = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n\n# Cross-validation for the stacking model\nscores = cross_val_score(stacking_model, X_train, y_train, cv=5)\n\nprint(f'Stacking model cross-validation scores: {scores}')\nprint(f'Mean accuracy: {scores.mean() * 100:.2f}%')\n","metadata":{"execution":{"iopub.status.busy":"2024-09-11T14:00:25.002885Z","iopub.execute_input":"2024-09-11T14:00:25.003376Z","iopub.status.idle":"2024-09-11T14:00:53.077155Z","shell.execute_reply.started":"2024-09-11T14:00:25.003332Z","shell.execute_reply":"2024-09-11T14:00:53.074726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a new feature combining Pclass and Fare\nX_train['Pclass_Fare'] = X_train['Pclass'] * X_train['Fare']\nX_test['Pclass_Fare'] = X_test['Pclass'] * X_test['Fare']\n","metadata":{"execution":{"iopub.status.busy":"2024-09-11T14:01:19.612970Z","iopub.execute_input":"2024-09-11T14:01:19.613423Z","iopub.status.idle":"2024-09-11T14:01:19.623236Z","shell.execute_reply.started":"2024-09-11T14:01:19.613381Z","shell.execute_reply":"2024-09-11T14:01:19.621916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\n\nskf = StratifiedKFold(n_splits=5)\nscores = cross_val_score(rf_model, X_train, y_train, cv=skf)\n\nprint(f'StratifiedKFold cross-validation scores: {scores}')\nprint(f'Mean accuracy: {scores.mean() * 100:.2f}%')\n","metadata":{"execution":{"iopub.status.busy":"2024-09-11T14:01:30.685611Z","iopub.execute_input":"2024-09-11T14:01:30.686062Z","iopub.status.idle":"2024-09-11T14:01:31.915627Z","shell.execute_reply.started":"2024-09-11T14:01:30.686020Z","shell.execute_reply":"2024-09-11T14:01:31.914384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Re-train the best Random Forest model from GridSearchCV\nbest_rf_model = RandomForestClassifier(\n    n_estimators=200, max_depth=20, min_samples_leaf=2, min_samples_split=10, random_state=42\n)\n\n# Train the model on the entire training set\nbest_rf_model.fit(X_train, y_train)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-11T14:03:36.780046Z","iopub.execute_input":"2024-09-11T14:03:36.780563Z","iopub.status.idle":"2024-09-11T14:03:37.250395Z","shell.execute_reply.started":"2024-09-11T14:03:36.780514Z","shell.execute_reply":"2024-09-11T14:03:37.249150Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make predictions on the test set\ntest_predictions = best_rf_model.predict(X_test)\n\n# Create a submission DataFrame\nsubmission = pd.DataFrame({\n    'PassengerId': test_df['PassengerId'],\n    'Survived': test_predictions\n})\n","metadata":{"execution":{"iopub.status.busy":"2024-09-11T14:03:58.780618Z","iopub.execute_input":"2024-09-11T14:03:58.781027Z","iopub.status.idle":"2024-09-11T14:03:58.813964Z","shell.execute_reply.started":"2024-09-11T14:03:58.780991Z","shell.execute_reply":"2024-09-11T14:03:58.812609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the submission to a CSV file\nsubmission.to_csv('submission.csv', index=False)\n\nprint(\"Submission file created successfully.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-11T14:04:20.476073Z","iopub.execute_input":"2024-09-11T14:04:20.476520Z","iopub.status.idle":"2024-09-11T14:04:20.488145Z","shell.execute_reply.started":"2024-09-11T14:04:20.476455Z","shell.execute_reply":"2024-09-11T14:04:20.486755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\nimport xgboost as xgb\n\n# Paramètres possibles pour XGBoost\nparam_dist = {\n    'n_estimators': [100, 300, 500],\n    'max_depth': [3, 5, 10, 15],\n    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n    'subsample': [0.6, 0.8, 1.0],\n    'colsample_bytree': [0.6, 0.8, 1.0],\n    'gamma': [0, 1, 5],\n    'reg_alpha': [0, 0.01, 0.1, 1],\n    'reg_lambda': [0.01, 0.1, 1]\n}\n\n# Initialiser XGBoost\nxgb_model = xgb.XGBClassifier(random_state=42)\n\n# Randomized Search avec 5-fold cross-validation\nrandom_search = RandomizedSearchCV(xgb_model, param_distributions=param_dist, n_iter=20, cv=5, verbose=2, n_jobs=-1, random_state=42)\nrandom_search.fit(X_train, y_train)\n\n# Afficher les meilleurs hyperparamètres et la meilleure précision\nprint(f\"Best hyperparameters: {random_search.best_params_}\")\nprint(f\"Best cross-validation accuracy: {random_search.best_score_ * 100:.2f}%\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-11T14:37:32.325711Z","iopub.execute_input":"2024-09-11T14:37:32.326213Z","iopub.status.idle":"2024-09-11T14:37:41.519566Z","shell.execute_reply.started":"2024-09-11T14:37:32.326173Z","shell.execute_reply":"2024-09-11T14:37:41.518227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import lightgbm as lgb\nfrom sklearn.model_selection import cross_val_score\n\n# Initialiser LightGBM\nlgb_model = lgb.LGBMClassifier(n_estimators=300, max_depth=10, learning_rate=0.05, random_state=42)\n\n# Validation croisée sur LightGBM\nscores = cross_val_score(lgb_model, X_train, y_train, cv=5)\n\nprint(f'LightGBM cross-validation scores: {scores}')\nprint(f'Mean accuracy: {scores.mean() * 100:.2f}%')\n","metadata":{"execution":{"iopub.status.busy":"2024-09-11T14:39:39.532222Z","iopub.execute_input":"2024-09-11T14:39:39.533054Z","iopub.status.idle":"2024-09-11T14:39:41.970003Z","shell.execute_reply.started":"2024-09-11T14:39:39.532979Z","shell.execute_reply":"2024-09-11T14:39:41.968474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Binning Age and Fare\ntrain_df['FareBin'] = pd.cut(train_df['Fare'], bins=[0, 8, 15, 31, 1000], labels=[0, 1, 2, 3])\ntest_df['FareBin'] = pd.cut(test_df['Fare'], bins=[0, 8, 15, 31, 1000], labels=[0, 1, 2, 3])\n\ntrain_df['AgeBin'] = pd.cut(train_df['Age'], bins=[0, 12, 20, 40, 60, 80], labels=[0, 1, 2, 3, 4])\ntest_df['AgeBin'] = pd.cut(test_df['Age'], bins=[0, 12, 20, 40, 60, 80], labels=[0, 1, 2, 3, 4])\n","metadata":{"execution":{"iopub.status.busy":"2024-09-11T14:40:43.499355Z","iopub.execute_input":"2024-09-11T14:40:43.500055Z","iopub.status.idle":"2024-09-11T14:40:43.516650Z","shell.execute_reply.started":"2024-09-11T14:40:43.500008Z","shell.execute_reply":"2024-09-11T14:40:43.515412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Interaction entre Pclass et Fare\ntrain_df['Pclass_Fare'] = train_df['Pclass'] * train_df['Fare']\ntest_df['Pclass_Fare'] = test_df['Pclass'] * test_df['Fare']\n","metadata":{"execution":{"iopub.status.busy":"2024-09-11T14:41:00.325772Z","iopub.execute_input":"2024-09-11T14:41:00.326212Z","iopub.status.idle":"2024-09-11T14:41:00.334585Z","shell.execute_reply.started":"2024-09-11T14:41:00.326169Z","shell.execute_reply":"2024-09-11T14:41:00.333496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Séparation des données en fonction du sexe\ntrain_femmes = train_df[train_df['Sex'] == 1]  # Femmes\ntrain_hommes = train_df[train_df['Sex'] == 0]  # Hommes\n\ntest_femmes = test_df[test_df['Sex'] == 1]\ntest_hommes = test_df[test_df['Sex'] == 0]\n","metadata":{"execution":{"iopub.status.busy":"2024-09-11T14:44:06.571173Z","iopub.execute_input":"2024-09-11T14:44:06.571684Z","iopub.status.idle":"2024-09-11T14:44:06.589267Z","shell.execute_reply.started":"2024-09-11T14:44:06.571632Z","shell.execute_reply":"2024-09-11T14:44:06.587628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Vérifier les valeurs manquantes dans X_train_femmes\nprint(X_train_femmes.isnull().sum())\n","metadata":{"execution":{"iopub.status.busy":"2024-09-11T14:45:03.525656Z","iopub.execute_input":"2024-09-11T14:45:03.526095Z","iopub.status.idle":"2024-09-11T14:45:03.534532Z","shell.execute_reply.started":"2024-09-11T14:45:03.526046Z","shell.execute_reply":"2024-09-11T14:45:03.533136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Réentraîner le modèle après avoir traité les NaN\nrf_model_femmes.fit(X_train_femmes, y_train_femmes)\n\n# Prédictions pour les femmes\npredictions_femmes = rf_model_femmes.predict(X_test_femmes)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-11T14:45:47.330274Z","iopub.execute_input":"2024-09-11T14:45:47.330708Z","iopub.status.idle":"2024-09-11T14:45:47.912589Z","shell.execute_reply.started":"2024-09-11T14:45:47.330665Z","shell.execute_reply":"2024-09-11T14:45:47.911143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Séparation des données en fonction du sexe\ntrain_hommes = train_df[train_df['Sex'] == 0]  # Hommes\ntest_hommes = test_df[test_df['Sex'] == 0]\n\n# Sélection des features pour les hommes\nX_train_hommes = train_hommes[['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'FamilySize', 'Title', 'FareBin', 'AgeBin', 'Pclass_Fare']]\ny_train_hommes = train_hommes['Survived']\n\nX_test_hommes = test_hommes[['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'FamilySize', 'Title', 'FareBin', 'AgeBin', 'Pclass_Fare']]\n","metadata":{"execution":{"iopub.status.busy":"2024-09-11T14:50:12.280347Z","iopub.execute_input":"2024-09-11T14:50:12.281539Z","iopub.status.idle":"2024-09-11T14:50:12.297694Z","shell.execute_reply.started":"2024-09-11T14:50:12.281440Z","shell.execute_reply":"2024-09-11T14:50:12.296205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Remplir les valeurs manquantes dans 'Age' et 'Fare'\nX_train_hommes['Age'].fillna(X_train_hommes['Age'].median(), inplace=True)\nX_train_hommes['Fare'].fillna(X_train_hommes['Fare'].median(), inplace=True)\n\n# Remplir les NaN dans 'Title'\nX_train_hommes['Title'].fillna(X_train_hommes['Title'].mode()[0], inplace=True)\n\n# Appliquer les mêmes transformations au jeu de test des hommes\nX_test_hommes['Age'].fillna(X_test_hommes['Age'].median(), inplace=True)\nX_test_hommes['Fare'].fillna(X_test_hommes['Fare'].median(), inplace=True)\nX_test_hommes['Title'].fillna(X_test_hommes['Title'].mode()[0], inplace=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-11T14:50:21.127940Z","iopub.execute_input":"2024-09-11T14:50:21.129127Z","iopub.status.idle":"2024-09-11T14:50:21.145012Z","shell.execute_reply.started":"2024-09-11T14:50:21.129068Z","shell.execute_reply":"2024-09-11T14:50:21.143379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Vérifier les valeurs manquantes dans X_train_hommes\nprint(X_train_hommes.isnull().sum())\n","metadata":{"execution":{"iopub.status.busy":"2024-09-11T14:51:12.969954Z","iopub.execute_input":"2024-09-11T14:51:12.971047Z","iopub.status.idle":"2024-09-11T14:51:12.979943Z","shell.execute_reply.started":"2024-09-11T14:51:12.970984Z","shell.execute_reply":"2024-09-11T14:51:12.978465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Remplir les valeurs manquantes dans 'FareBin' en utilisant la valeur la plus fréquente (mode)\nX_train_hommes['FareBin'].fillna(X_train_hommes['FareBin'].mode()[0], inplace=True)\nX_test_hommes['FareBin'].fillna(X_test_hommes['FareBin'].mode()[0], inplace=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-11T14:51:48.264538Z","iopub.execute_input":"2024-09-11T14:51:48.265002Z","iopub.status.idle":"2024-09-11T14:51:48.278897Z","shell.execute_reply.started":"2024-09-11T14:51:48.264958Z","shell.execute_reply":"2024-09-11T14:51:48.277732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Entraîner le modèle pour les hommes\nrf_model_hommes = RandomForestClassifier(n_estimators=300, max_depth=10, random_state=42)\nrf_model_hommes.fit(X_train_hommes, y_train_hommes)\n\n# Prédictions pour les hommes\npredictions_hommes = rf_model_hommes.predict(X_test_hommes)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-11T14:52:02.409400Z","iopub.execute_input":"2024-09-11T14:52:02.410618Z","iopub.status.idle":"2024-09-11T14:52:03.099292Z","shell.execute_reply.started":"2024-09-11T14:52:02.410570Z","shell.execute_reply":"2024-09-11T14:52:03.098033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
